{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de863407",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ed4e902",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "D = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7fbf2612",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randn(N, D)\n",
    "half = int(N/2)\n",
    "\n",
    "X[:half, :] = X[:half, :] - 2 * np.ones((half, D))\n",
    "X[half:, :] = X[half:, :] + 2 * np.ones((half, D))\n",
    "\n",
    "ones = np.ones((N, 1), dtype='uint8')\n",
    "Xb = np.concatenate((ones, X), axis = 1)\n",
    "T = np.array([0] * half + [1] * half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c920400e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(a) :\n",
    "    return 1 / (1 + np.exp(-a))\n",
    "\n",
    "def cross_entropy(T, Y) :\n",
    "    E = 0\n",
    "    for i in range(len(T)) : \n",
    "        if T[i] == 1:\n",
    "            E -= np.log(Y[i])\n",
    "        else :\n",
    "            E -= np.log(1 - Y[i])\n",
    "    return E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7ea6988e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross entropy is :  7.352943595221198\n"
     ]
    }
   ],
   "source": [
    "#randomly initalizing the weights\n",
    "w = np.random.rand(D + 1)\n",
    "\n",
    "#calculate the model output \n",
    "z = Xb.dot(w)\n",
    "\n",
    "#apply the activation function\n",
    "Y = sigmoid(z)\n",
    "\n",
    "print('The cross entropy is : ', cross_entropy(T, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8f791b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross entropy is 7.352943595221198\n",
      "The cross entropy is 3.985928936205253\n",
      "The cross entropy is 1.887162088235055\n",
      "The cross entropy is 1.8789858125727221\n",
      "The cross entropy is 1.8736839239963003\n",
      "The cross entropy is 1.8663804498882546\n",
      "The cross entropy is 1.8616288345811838\n",
      "The cross entropy is 1.8550412860103886\n",
      "The cross entropy is 1.8508496330956958\n",
      "The cross entropy is 1.8448819041657996\n",
      "The cross entropy is 1.8412784079712459\n",
      "The cross entropy is 1.8358682833099096\n",
      "The cross entropy is 1.832896886300021\n",
      "The cross entropy is 1.8279997774436487\n",
      "The cross entropy is 1.8257196954998103\n",
      "The cross entropy is 1.8212974581827666\n",
      "The cross entropy is 1.8197843275583625\n",
      "The cross entropy is 1.8157962310397007\n",
      "The cross entropy is 1.8151444787236655\n",
      "The cross entropy is 1.8115385685891374\n",
      "The cross entropy is 1.8118645768647639\n",
      "The cross entropy is 1.8085682428859202\n",
      "The cross entropy is 1.8100136001923612\n",
      "The cross entropy is 1.8069225740920432\n",
      "The cross entropy is 1.8096562101529743\n",
      "The cross entropy is 1.80662181879812\n",
      "The cross entropy is 1.8108392152468062\n",
      "The cross entropy is 1.8076548271163269\n",
      "The cross entropy is 1.8135720320120834\n",
      "The cross entropy is 1.809961461964094\n",
      "The cross entropy is 1.8178017681788283\n",
      "The cross entropy is 1.8134147239795095\n",
      "The cross entropy is 1.8233871341479897\n",
      "The cross entropy is 1.8178085381278484\n",
      "The cross entropy is 1.8300797876269785\n",
      "The cross entropy is 1.822859022344697\n",
      "The cross entropy is 1.837524386292237\n",
      "The cross entropy is 1.8282253169482965\n",
      "The cross entropy is 1.8452860120950552\n",
      "The cross entropy is 1.83354944672862\n",
      "The cross entropy is 1.852904099389422\n",
      "The cross entropy is 1.8385055516233066\n",
      "The cross entropy is 1.8599591682953915\n",
      "The cross entropy is 1.8428429071046253\n",
      "The cross entropy is 1.8661307639416669\n",
      "The cross entropy is 1.8464092559870828\n",
      "The cross entropy is 1.8712284045937981\n",
      "The cross entropy is 1.8491500921736705\n",
      "The cross entropy is 1.8751901123368437\n",
      "The cross entropy is 1.8510894335869679\n",
      "The final weight is :  [-4.60303049  5.96222902  6.32405947]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1\n",
    "\n",
    "for i in range(500):\n",
    "    if i % 10 == 0:\n",
    "        print('The cross entropy is', cross_entropy(T, Y))\n",
    "        \n",
    "        w -= learning_rate * np.dot((Y - T).T, Xb)\n",
    "        Y = sigmoid(Xb.dot(w))\n",
    "        \n",
    "print('The final weight is : ', w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7cee30c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8508553263344312"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b553e139",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
