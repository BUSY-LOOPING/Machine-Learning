{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc6a2cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import importlib\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5d06d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from util.ipynb\n",
      "importing Jupyter notebook from process.ipynb\n"
     ]
    }
   ],
   "source": [
    "import util\n",
    "import process\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8597f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from process import get_labels, get_train_test_data, get_data, get_binary_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "001f9be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import sigmoid, bin_cross_entropy, error_rate, relu, init_weight_bias, classification_rate, cost, to_indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8d16711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from util.ipynb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'util' from 'util.ipynb'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(util)\n",
    "# reload(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d7e43012",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN(object):\n",
    "    def __init__(self, M) :  #no of hidden units\n",
    "        self.M = M\n",
    "        \n",
    "    def fit(self, X, Y, learning_rate= 5*10e-7, reg = 1.0, epochs = 10000, show_fig = False, usecupy = False, activation = 'relu') :\n",
    "        X, Y = shuffle(X, Y)\n",
    "        Xvalid, Yvalid = X[-1000:], Y[-1000:]\n",
    "        X, Y = X[:-1000], Y[:-1000]\n",
    "        \n",
    "        N, D = X.shape\n",
    "        if usecupy :\n",
    "            module = importlib.import_module('cupy')\n",
    "        else :\n",
    "            module = importlib.import_module('numpy')\n",
    "        X, Y = module.array(X), module.array(Y)\n",
    "        print(Y)\n",
    "        Xvalid, Yvalid = module.array(Xvalid), module.array(Yvalid)\n",
    "            \n",
    "        self.W1, self.b1 = module.random.randn(D, self.M)/ module.sqrt(D + self.M), module.zeros(self.M)\n",
    "        self.W2, self.b2 = module.random.randn(self.M, 1) / module.sqrt(self.M), 0\n",
    "        \n",
    "        costs_valid = []\n",
    "        costs = []\n",
    "        best_val_error = None\n",
    "        for i in range(epochs) :\n",
    "            #forward propogation\n",
    "            pY, Z = self.forward(X, activation, usecupy = usecupy)\n",
    "            c = bin_cross_entropy(Y, pY, usecupy = usecupy)\n",
    "            if usecupy:\n",
    "                c = c.get()\n",
    "            costs.append(c)\n",
    "            \n",
    "            #gradient-descent\n",
    "            pY_Y = Y - pY\n",
    "            self.W2 += learning_rate * (Z.T.dot(pY_Y) - reg * self.W2)\n",
    "            self.b2 += learning_rate * ((pY_Y).sum(axis = 0) - reg * self.b2)\n",
    "            if activation == 'relu' :\n",
    "                dz = module.outer(pY_Y, self.W2) * (Z>0)\n",
    "            elif activation == 'tanh' :\n",
    "                dz = module.outer(pY_Y, self.W2) * (1 - Z * Z)\n",
    "            self.W1 += learning_rate * X.T.dot((pY_Y.dot(self.W2.T) * dz) - reg * self.W1)\n",
    "            self.b1 += learning_rate * ((pY_Y.dot(self.W2.T) * dz).sum(axis = 0) - reg * self.b1)\n",
    "            \n",
    "            pYvalid, _ = self.forward(Xvalid, activation, usecupy = usecupy)\n",
    "            c_valid = bin_cross_entropy(Yvalid, pYvalid, usecupy = usecupy)\n",
    "            if usecupy:\n",
    "                c_valid = c_valid.get()\n",
    "                e = error_rate(Yvalid.get(), pYvalid.get())\n",
    "            else :\n",
    "                e = error_rate(Yvalid, pYvalid)\n",
    "            costs_valid.append(c_valid)\n",
    "            \n",
    "            \n",
    "            if best_val_error == None or e < best_val_error:\n",
    "                best_val_error = e\n",
    "                \n",
    "            if i % 20 == 0 :\n",
    "                print(f'i = {i}, cost = {c}, cost_valid = {c_valid}, error = {e}')\n",
    "        print('Best val error', best_val_error)\n",
    "\n",
    "        if show_fig == True :\n",
    "            plt.figure()\n",
    "            plt.title('Costs')\n",
    "            plt.plot(costs, label = 'Training costs')\n",
    "            plt.plot(costs_valid, label = 'Validation costs')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "                \n",
    "    def forward(self, X, activation = 'relu', usecupy = False) :\n",
    "        if usecupy :\n",
    "            module = importlib.import_module('cupy')\n",
    "        else :\n",
    "            module = importlib.import_module('numpy')\n",
    "        alpha = X.dot(self.W1) + self.b1\n",
    "            \n",
    "        if activation == 'relu' :\n",
    "            Z = relu(alpha)\n",
    "        elif activation == 'tanh' :\n",
    "            Z = module.tanh(alpha)\n",
    "        return sigmoid(Z.dot(self.W2) + self.b2), Z\n",
    "    \n",
    "    def predict(self, X, activation) :\n",
    "        pY , _ = forward(X, activation)\n",
    "        return np.round(pY)\n",
    "    \n",
    "    def score(self, X, Y) :\n",
    "        if str(type(X)) == \"<class 'cupy.ndarray'>\" :\n",
    "            X = X.get()\n",
    "        if str(type(Y)) == \"<class 'cupy.ndarray'>\" :\n",
    "            Y = Y.get()\n",
    "        prediction = self.predict(X)\n",
    "        return classification_rate(Y, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91ba1ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = get_binary_data(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f232b50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:43: RuntimeWarning: invalid value encountered in log\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (100,1) doesn't match the broadcast shape (100,2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [40], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m Y_ind \u001b[38;5;241m=\u001b[39m to_indicator(Y, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m ANN(\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X, Y_ind, show_fig\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, usecupy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m, learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0001\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtanh\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn [39], line 35\u001b[0m, in \u001b[0;36mANN.fit\u001b[1;34m(self, X, Y, learning_rate, reg, epochs, show_fig, usecupy, activation)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m#gradient-descent\u001b[39;00m\n\u001b[0;32m     34\u001b[0m pY_Y \u001b[38;5;241m=\u001b[39m Y \u001b[38;5;241m-\u001b[39m pY\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW2 \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m learning_rate \u001b[38;5;241m*\u001b[39m (Z\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mdot(pY_Y) \u001b[38;5;241m-\u001b[39m reg \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW2)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb2 \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m learning_rate \u001b[38;5;241m*\u001b[39m ((pY_Y)\u001b[38;5;241m.\u001b[39msum(axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m reg \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb2)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m activation \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m :\n",
      "\u001b[1;31mValueError\u001b[0m: non-broadcastable output operand with shape (100,1) doesn't match the broadcast shape (100,2)"
     ]
    }
   ],
   "source": [
    "Y_ind = to_indicator(Y, 2)\n",
    "model = ANN(100)\n",
    "model.fit(X, Y_ind, show_fig=True, usecupy=False, epochs = 50, learning_rate = 0.0001, activation='tanh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8c34bd5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8355,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4cb82be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.529510260438744\n"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(10, 2)\n",
    "y = np.random.rand(10, 2)\n",
    "print(bin_cross_entropy(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba164316",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhruv\\AppData\\Local\\Temp\\ipykernel_11960\\4152586882.py:3: RuntimeWarning: divide by zero encountered in log\n",
      "  np.log(z)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([       -inf,  0.65752883,  0.25693697,        -inf, -2.07644508,\n",
       "              -inf, -2.53857501,        -inf, -1.67480696, -0.74095672])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.randn(10)\n",
    "z = np.maximum(0, x)\n",
    "np.log(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c667bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00837402,  1.93001703,  1.29296363, -0.74679359,  0.12537512,\n",
       "       -1.14625044,  0.07897886, -0.70470021,  0.18734434,  0.47665767])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58f7651d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.        ,  1.93001703,  1.29296363, -0.        ,  0.12537512,\n",
       "       -0.        ,  0.07897886, -0.        ,  0.18734434,  0.47665767])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x > 0) * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fafca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1435e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhruv\\AppData\\Local\\Temp\\ipykernel_19892\\2933082444.py:1: RuntimeWarning: divide by zero encountered in log\n",
      "  np.log(0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-inf"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d2b45d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
